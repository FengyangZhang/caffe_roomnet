I0516 19:48:08.701974 119433 caffe.cpp:275] Use GPU with device ID 1
I0516 19:48:08.731173 119433 caffe.cpp:279] GPU device name: Tesla K40c
I0516 19:48:09.176542 119433 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: models/roomnet/roomnet_inference.prototxt
I0516 19:48:09.176625 119433 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0516 19:48:09.177695 119433 net.cpp:51] Initializing net from parameters: 
name: "RoomNet"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DataHeatmapTest"
  top: "data"
  heatmap_test_param {
    batchsize: 1
    root_img_dir: "/data01/vision_rd/zhangfengyang/roomnet/LSUN/images/"
    source: "/data01/vision_rd/zhangfengyang/roomnet/caffe_roomnet/train/train_single.txt"
    outsize: 320
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_2_bn"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2_2_bn"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_2_bn"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3_3_bn"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool3_drop"
  type: "Dropout"
  bottom: "pool3"
  top: "pool3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_bn"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_bn"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool4_drop"
  type: "Dropout"
  bottom: "pool4"
  top: "pool4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_bn"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool5_drop"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc_1024"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc_1024"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_512"
  type: "InnerProduct"
  bottom: "fc_1024"
  top: "fc_512"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc_11"
  type: "InnerProduct"
  bottom: "fc_512"
  top: "fc_11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "upsample5"
  upsample_param {
    scale: 2
    upsample_h: 20
    upsample_w: 20
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "upsample5"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_3_D_bn"
  type: "BatchNorm"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_2_D_bn"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv5_1_D_bn"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "conv5_1_D_drop"
  type: "Dropout"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "upsample4"
  upsample_param {
    scale: 2
    upsample_h: 40
    upsample_w: 40
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "upsample4"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_3_D_bn"
  type: "BatchNorm"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_2_D_bn"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_1_D_bn"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "conv_final_64_D"
  type: "Convolution"
  bottom: "conv4_1_D"
  top: "conv_final_64_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_final_64_D_bn"
  type: "BatchNorm"
  bottom: "conv_final_64_D"
  top: "conv_final_64_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu_final_64_D"
  type: "ReLU"
  bottom: "conv_final_64_D"
  top: "conv_final_64_D"
}
layer {
  name: "conv_final_48_D"
  type: "Convolution"
  bottom: "conv_final_64_D"
  top: "conv_final_48_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv4_final_48_D_bn"
  type: "BatchNorm"
  bottom: "conv_final_48_D"
  top: "conv_final_48_D"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "relu_final_48_D"
  type: "ReLU"
  bottom: "conv_final_48_D"
  top: "conv_final_48_D"
}
layer {
  name: "heatmap_visualize"
  type: "HeatmapVisualize"
  bottom: "conv_final_48_D"
  top: "heatmap_visualize"
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_11"
  top: "prob"
  softmax_param {
    engine: CAFFE
  }
}
I0516 19:48:09.178732 119433 layer_factory.hpp:77] Creating layer data
I0516 19:48:09.178871 119433 net.cpp:84] Creating Layer data
I0516 19:48:09.178900 119433 net.cpp:380] data -> data
I0516 19:48:09.179018 119433 data_heatmap_test.cpp:51] Loading annotation from /data01/vision_rd/zhangfengyang/roomnet/caffe_roomnet/train/train_single.txt
I0516 19:48:09.584652 119433 data_heatmap_test.cpp:74] output data size: 1,3,320,320
I0516 19:48:09.587548 119433 roomnet_test_layer.cpp:58] Initializing prefetch
I0516 19:48:09.588050 119433 roomnet_test_layer.cpp:61] Prefetch initialized.
I0516 19:48:09.588065 119433 net.cpp:122] Setting up data
I0516 19:48:09.588104 119433 net.cpp:129] Top shape: 1 3 320 320 (307200)
I0516 19:48:09.588110 119433 net.cpp:137] Memory required for data: 1228800
I0516 19:48:09.588142 119433 layer_factory.hpp:77] Creating layer conv1_1
I0516 19:48:09.588223 119433 net.cpp:84] Creating Layer conv1_1
I0516 19:48:09.588264 119433 net.cpp:406] conv1_1 <- data
I0516 19:48:09.588325 119433 net.cpp:380] conv1_1 -> conv1_1
I0516 19:48:09.590301 119436 data_heatmap_test.cpp:111] img: /data01/vision_rd/zhangfengyang/roomnet/LSUN/images/sun_adxkgdkocvlrjoil.jpg
I0516 19:48:09.616838 119436 data_heatmap_test.cpp:147] Resizing output image.
I0516 19:48:09.616904 119436 data_heatmap_test.cpp:152] resizeFact_x: 0.3125
I0516 19:48:09.616953 119436 data_heatmap_test.cpp:153] resizeFact_y: 0.416667
I0516 19:48:09.632395 119436 data_heatmap_test.cpp:165] storing image
I0516 19:48:09.637698 119436 data_heatmap_test.cpp:177] next image
I0516 19:48:09.637800 119436 data_heatmap_test.cpp:185] Prefetch batch: 47 ms.
I0516 19:48:09.643198 119436 data_heatmap_test.cpp:111] img: /data01/vision_rd/zhangfengyang/roomnet/LSUN/images/sun_adxkgdkocvlrjoil.jpg
I0516 19:48:09.662677 119436 data_heatmap_test.cpp:147] Resizing output image.
I0516 19:48:09.662731 119436 data_heatmap_test.cpp:152] resizeFact_x: 0.3125
I0516 19:48:09.662751 119436 data_heatmap_test.cpp:153] resizeFact_y: 0.416667
I0516 19:48:09.675086 119436 data_heatmap_test.cpp:165] storing image
I0516 19:48:09.679451 119436 data_heatmap_test.cpp:177] next image
I0516 19:48:09.679508 119436 data_heatmap_test.cpp:185] Prefetch batch: 36 ms.
I0516 19:48:09.779247 119433 net.cpp:122] Setting up conv1_1
I0516 19:48:09.779292 119433 net.cpp:129] Top shape: 1 64 320 320 (6553600)
I0516 19:48:09.779299 119433 net.cpp:137] Memory required for data: 27443200
I0516 19:48:09.779384 119433 layer_factory.hpp:77] Creating layer conv1_1_bn
I0516 19:48:09.779433 119433 net.cpp:84] Creating Layer conv1_1_bn
I0516 19:48:09.779446 119433 net.cpp:406] conv1_1_bn <- conv1_1
I0516 19:48:09.779474 119433 net.cpp:367] conv1_1_bn -> conv1_1 (in-place)
I0516 19:48:09.779911 119433 net.cpp:122] Setting up conv1_1_bn
I0516 19:48:09.779924 119433 net.cpp:129] Top shape: 1 64 320 320 (6553600)
I0516 19:48:09.779928 119433 net.cpp:137] Memory required for data: 53657600
I0516 19:48:09.779963 119433 layer_factory.hpp:77] Creating layer relu1_1
I0516 19:48:09.779994 119433 net.cpp:84] Creating Layer relu1_1
I0516 19:48:09.780001 119433 net.cpp:406] relu1_1 <- conv1_1
I0516 19:48:09.780016 119433 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0516 19:48:09.780673 119433 net.cpp:122] Setting up relu1_1
I0516 19:48:09.780691 119433 net.cpp:129] Top shape: 1 64 320 320 (6553600)
I0516 19:48:09.780697 119433 net.cpp:137] Memory required for data: 79872000
I0516 19:48:09.780705 119433 layer_factory.hpp:77] Creating layer conv1_2
I0516 19:48:09.780742 119433 net.cpp:84] Creating Layer conv1_2
I0516 19:48:09.780753 119433 net.cpp:406] conv1_2 <- conv1_1
I0516 19:48:09.780778 119433 net.cpp:380] conv1_2 -> conv1_2
I0516 19:48:09.787467 119433 net.cpp:122] Setting up conv1_2
I0516 19:48:09.787488 119433 net.cpp:129] Top shape: 1 64 320 320 (6553600)
I0516 19:48:09.787494 119433 net.cpp:137] Memory required for data: 106086400
I0516 19:48:09.787511 119433 layer_factory.hpp:77] Creating layer conv1_2_bn
I0516 19:48:09.787533 119433 net.cpp:84] Creating Layer conv1_2_bn
I0516 19:48:09.787555 119433 net.cpp:406] conv1_2_bn <- conv1_2
I0516 19:48:09.787575 119433 net.cpp:367] conv1_2_bn -> conv1_2 (in-place)
I0516 19:48:09.788017 119433 net.cpp:122] Setting up conv1_2_bn
I0516 19:48:09.788030 119433 net.cpp:129] Top shape: 1 64 320 320 (6553600)
I0516 19:48:09.788035 119433 net.cpp:137] Memory required for data: 132300800
I0516 19:48:09.788064 119433 layer_factory.hpp:77] Creating layer relu1_2
I0516 19:48:09.788080 119433 net.cpp:84] Creating Layer relu1_2
I0516 19:48:09.788089 119433 net.cpp:406] relu1_2 <- conv1_2
I0516 19:48:09.788105 119433 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0516 19:48:09.788305 119433 net.cpp:122] Setting up relu1_2
I0516 19:48:09.788319 119433 net.cpp:129] Top shape: 1 64 320 320 (6553600)
I0516 19:48:09.788324 119433 net.cpp:137] Memory required for data: 158515200
I0516 19:48:09.788331 119433 layer_factory.hpp:77] Creating layer pool1
I0516 19:48:09.788357 119433 net.cpp:84] Creating Layer pool1
I0516 19:48:09.788365 119433 net.cpp:406] pool1 <- conv1_2
I0516 19:48:09.788386 119433 net.cpp:380] pool1 -> pool1
I0516 19:48:09.788468 119433 net.cpp:122] Setting up pool1
I0516 19:48:09.788486 119433 net.cpp:129] Top shape: 1 64 160 160 (1638400)
I0516 19:48:09.788491 119433 net.cpp:137] Memory required for data: 165068800
I0516 19:48:09.788498 119433 layer_factory.hpp:77] Creating layer conv2_1
I0516 19:48:09.788529 119433 net.cpp:84] Creating Layer conv2_1
I0516 19:48:09.788552 119433 net.cpp:406] conv2_1 <- pool1
I0516 19:48:09.788573 119433 net.cpp:380] conv2_1 -> conv2_1
I0516 19:48:09.798372 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6912
I0516 19:48:09.798959 119433 net.cpp:122] Setting up conv2_1
I0516 19:48:09.798985 119433 net.cpp:129] Top shape: 1 128 160 160 (3276800)
I0516 19:48:09.798991 119433 net.cpp:137] Memory required for data: 178176000
I0516 19:48:09.799016 119433 layer_factory.hpp:77] Creating layer conv2_1_bn
I0516 19:48:09.799055 119433 net.cpp:84] Creating Layer conv2_1_bn
I0516 19:48:09.799069 119433 net.cpp:406] conv2_1_bn <- conv2_1
I0516 19:48:09.799096 119433 net.cpp:367] conv2_1_bn -> conv2_1 (in-place)
I0516 19:48:09.799376 119433 net.cpp:122] Setting up conv2_1_bn
I0516 19:48:09.799388 119433 net.cpp:129] Top shape: 1 128 160 160 (3276800)
I0516 19:48:09.799393 119433 net.cpp:137] Memory required for data: 191283200
I0516 19:48:09.799413 119433 layer_factory.hpp:77] Creating layer relu2_1
I0516 19:48:09.799433 119433 net.cpp:84] Creating Layer relu2_1
I0516 19:48:09.799441 119433 net.cpp:406] relu2_1 <- conv2_1
I0516 19:48:09.799456 119433 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0516 19:48:09.799643 119433 net.cpp:122] Setting up relu2_1
I0516 19:48:09.799655 119433 net.cpp:129] Top shape: 1 128 160 160 (3276800)
I0516 19:48:09.799660 119433 net.cpp:137] Memory required for data: 204390400
I0516 19:48:09.799669 119433 layer_factory.hpp:77] Creating layer conv2_2
I0516 19:48:09.799700 119433 net.cpp:84] Creating Layer conv2_2
I0516 19:48:09.799710 119433 net.cpp:406] conv2_2 <- conv2_1
I0516 19:48:09.799731 119433 net.cpp:380] conv2_2 -> conv2_2
I0516 19:48:09.815987 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0516 19:48:09.816045 119433 net.cpp:122] Setting up conv2_2
I0516 19:48:09.816066 119433 net.cpp:129] Top shape: 1 128 160 160 (3276800)
I0516 19:48:09.816071 119433 net.cpp:137] Memory required for data: 217497600
I0516 19:48:09.816118 119433 layer_factory.hpp:77] Creating layer conv2_2_bn
I0516 19:48:09.816157 119433 net.cpp:84] Creating Layer conv2_2_bn
I0516 19:48:09.816170 119433 net.cpp:406] conv2_2_bn <- conv2_2
I0516 19:48:09.816193 119433 net.cpp:367] conv2_2_bn -> conv2_2 (in-place)
I0516 19:48:09.816473 119433 net.cpp:122] Setting up conv2_2_bn
I0516 19:48:09.816485 119433 net.cpp:129] Top shape: 1 128 160 160 (3276800)
I0516 19:48:09.816490 119433 net.cpp:137] Memory required for data: 230604800
I0516 19:48:09.816510 119433 layer_factory.hpp:77] Creating layer relu2_2
I0516 19:48:09.816529 119433 net.cpp:84] Creating Layer relu2_2
I0516 19:48:09.816539 119433 net.cpp:406] relu2_2 <- conv2_2
I0516 19:48:09.816553 119433 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0516 19:48:09.817199 119433 net.cpp:122] Setting up relu2_2
I0516 19:48:09.817216 119433 net.cpp:129] Top shape: 1 128 160 160 (3276800)
I0516 19:48:09.817222 119433 net.cpp:137] Memory required for data: 243712000
I0516 19:48:09.817234 119433 layer_factory.hpp:77] Creating layer pool2
I0516 19:48:09.817257 119433 net.cpp:84] Creating Layer pool2
I0516 19:48:09.817265 119433 net.cpp:406] pool2 <- conv2_2
I0516 19:48:09.817284 119433 net.cpp:380] pool2 -> pool2
I0516 19:48:09.817378 119433 net.cpp:122] Setting up pool2
I0516 19:48:09.817392 119433 net.cpp:129] Top shape: 1 128 80 80 (819200)
I0516 19:48:09.817397 119433 net.cpp:137] Memory required for data: 246988800
I0516 19:48:09.817404 119433 layer_factory.hpp:77] Creating layer conv3_1
I0516 19:48:09.817435 119433 net.cpp:84] Creating Layer conv3_1
I0516 19:48:09.817446 119433 net.cpp:406] conv3_1 <- pool2
I0516 19:48:09.817469 119433 net.cpp:380] conv3_1 -> conv3_1
I0516 19:48:09.849027 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 13824
I0516 19:48:09.849078 119433 net.cpp:122] Setting up conv3_1
I0516 19:48:09.849097 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.849102 119433 net.cpp:137] Memory required for data: 253542400
I0516 19:48:09.849128 119433 layer_factory.hpp:77] Creating layer conv3_1_bn
I0516 19:48:09.849175 119433 net.cpp:84] Creating Layer conv3_1_bn
I0516 19:48:09.849189 119433 net.cpp:406] conv3_1_bn <- conv3_1
I0516 19:48:09.849218 119433 net.cpp:367] conv3_1_bn -> conv3_1 (in-place)
I0516 19:48:09.849457 119433 net.cpp:122] Setting up conv3_1_bn
I0516 19:48:09.849483 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.849488 119433 net.cpp:137] Memory required for data: 260096000
I0516 19:48:09.849508 119433 layer_factory.hpp:77] Creating layer relu3_1
I0516 19:48:09.849525 119433 net.cpp:84] Creating Layer relu3_1
I0516 19:48:09.849534 119433 net.cpp:406] relu3_1 <- conv3_1
I0516 19:48:09.849550 119433 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0516 19:48:09.849737 119433 net.cpp:122] Setting up relu3_1
I0516 19:48:09.849750 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.849756 119433 net.cpp:137] Memory required for data: 266649600
I0516 19:48:09.849762 119433 layer_factory.hpp:77] Creating layer conv3_2
I0516 19:48:09.849792 119433 net.cpp:84] Creating Layer conv3_2
I0516 19:48:09.849803 119433 net.cpp:406] conv3_2 <- conv3_1
I0516 19:48:09.849827 119433 net.cpp:380] conv3_2 -> conv3_2
I0516 19:48:09.911635 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0516 19:48:09.911687 119433 net.cpp:122] Setting up conv3_2
I0516 19:48:09.911710 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.911715 119433 net.cpp:137] Memory required for data: 273203200
I0516 19:48:09.911746 119433 layer_factory.hpp:77] Creating layer conv3_2_bn
I0516 19:48:09.911790 119433 net.cpp:84] Creating Layer conv3_2_bn
I0516 19:48:09.911805 119433 net.cpp:406] conv3_2_bn <- conv3_2
I0516 19:48:09.911837 119433 net.cpp:367] conv3_2_bn -> conv3_2 (in-place)
I0516 19:48:09.912078 119433 net.cpp:122] Setting up conv3_2_bn
I0516 19:48:09.912091 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.912096 119433 net.cpp:137] Memory required for data: 279756800
I0516 19:48:09.912118 119433 layer_factory.hpp:77] Creating layer relu3_2
I0516 19:48:09.912137 119433 net.cpp:84] Creating Layer relu3_2
I0516 19:48:09.912144 119433 net.cpp:406] relu3_2 <- conv3_2
I0516 19:48:09.912163 119433 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0516 19:48:09.912377 119433 net.cpp:122] Setting up relu3_2
I0516 19:48:09.912392 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.912398 119433 net.cpp:137] Memory required for data: 286310400
I0516 19:48:09.912406 119433 layer_factory.hpp:77] Creating layer conv3_3
I0516 19:48:09.912441 119433 net.cpp:84] Creating Layer conv3_3
I0516 19:48:09.912452 119433 net.cpp:406] conv3_3 <- conv3_2
I0516 19:48:09.912474 119433 net.cpp:380] conv3_3 -> conv3_3
I0516 19:48:09.975709 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0516 19:48:09.975764 119433 net.cpp:122] Setting up conv3_3
I0516 19:48:09.975783 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.975788 119433 net.cpp:137] Memory required for data: 292864000
I0516 19:48:09.975812 119433 layer_factory.hpp:77] Creating layer conv3_3_bn
I0516 19:48:09.975852 119433 net.cpp:84] Creating Layer conv3_3_bn
I0516 19:48:09.975865 119433 net.cpp:406] conv3_3_bn <- conv3_3
I0516 19:48:09.975894 119433 net.cpp:367] conv3_3_bn -> conv3_3 (in-place)
I0516 19:48:09.976121 119433 net.cpp:122] Setting up conv3_3_bn
I0516 19:48:09.976135 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.976140 119433 net.cpp:137] Memory required for data: 299417600
I0516 19:48:09.976177 119433 layer_factory.hpp:77] Creating layer relu3_3
I0516 19:48:09.976197 119433 net.cpp:84] Creating Layer relu3_3
I0516 19:48:09.976205 119433 net.cpp:406] relu3_3 <- conv3_3
I0516 19:48:09.976220 119433 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0516 19:48:09.976945 119433 net.cpp:122] Setting up relu3_3
I0516 19:48:09.976963 119433 net.cpp:129] Top shape: 1 256 80 80 (1638400)
I0516 19:48:09.976969 119433 net.cpp:137] Memory required for data: 305971200
I0516 19:48:09.976976 119433 layer_factory.hpp:77] Creating layer pool3
I0516 19:48:09.976999 119433 net.cpp:84] Creating Layer pool3
I0516 19:48:09.977010 119433 net.cpp:406] pool3 <- conv3_3
I0516 19:48:09.977028 119433 net.cpp:380] pool3 -> pool3
I0516 19:48:09.977110 119433 net.cpp:122] Setting up pool3
I0516 19:48:09.977135 119433 net.cpp:129] Top shape: 1 256 40 40 (409600)
I0516 19:48:09.977140 119433 net.cpp:137] Memory required for data: 307609600
I0516 19:48:09.977147 119433 layer_factory.hpp:77] Creating layer pool3_drop
I0516 19:48:09.977174 119433 net.cpp:84] Creating Layer pool3_drop
I0516 19:48:09.977182 119433 net.cpp:406] pool3_drop <- pool3
I0516 19:48:09.977202 119433 net.cpp:367] pool3_drop -> pool3 (in-place)
I0516 19:48:09.977260 119433 net.cpp:122] Setting up pool3_drop
I0516 19:48:09.977272 119433 net.cpp:129] Top shape: 1 256 40 40 (409600)
I0516 19:48:09.977277 119433 net.cpp:137] Memory required for data: 309248000
I0516 19:48:09.977283 119433 layer_factory.hpp:77] Creating layer conv4_1
I0516 19:48:09.977315 119433 net.cpp:84] Creating Layer conv4_1
I0516 19:48:09.977325 119433 net.cpp:406] conv4_1 <- pool3
I0516 19:48:09.977346 119433 net.cpp:380] conv4_1 -> conv4_1
I0516 19:48:10.101318 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0516 19:48:10.101373 119433 net.cpp:122] Setting up conv4_1
I0516 19:48:10.101395 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.101402 119433 net.cpp:137] Memory required for data: 312524800
I0516 19:48:10.101431 119433 layer_factory.hpp:77] Creating layer conv4_1_bn
I0516 19:48:10.101470 119433 net.cpp:84] Creating Layer conv4_1_bn
I0516 19:48:10.101485 119433 net.cpp:406] conv4_1_bn <- conv4_1
I0516 19:48:10.101521 119433 net.cpp:367] conv4_1_bn -> conv4_1 (in-place)
I0516 19:48:10.101771 119433 net.cpp:122] Setting up conv4_1_bn
I0516 19:48:10.101784 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.101788 119433 net.cpp:137] Memory required for data: 315801600
I0516 19:48:10.101809 119433 layer_factory.hpp:77] Creating layer relu4_1
I0516 19:48:10.101827 119433 net.cpp:84] Creating Layer relu4_1
I0516 19:48:10.101836 119433 net.cpp:406] relu4_1 <- conv4_1
I0516 19:48:10.101851 119433 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0516 19:48:10.102049 119433 net.cpp:122] Setting up relu4_1
I0516 19:48:10.102063 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.102068 119433 net.cpp:137] Memory required for data: 319078400
I0516 19:48:10.102077 119433 layer_factory.hpp:77] Creating layer conv4_2
I0516 19:48:10.102109 119433 net.cpp:84] Creating Layer conv4_2
I0516 19:48:10.102120 119433 net.cpp:406] conv4_2 <- conv4_1
I0516 19:48:10.102144 119433 net.cpp:380] conv4_2 -> conv4_2
I0516 19:48:10.343205 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:10.343251 119433 net.cpp:122] Setting up conv4_2
I0516 19:48:10.343272 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.343278 119433 net.cpp:137] Memory required for data: 322355200
I0516 19:48:10.343307 119433 layer_factory.hpp:77] Creating layer conv4_2_bn
I0516 19:48:10.343349 119433 net.cpp:84] Creating Layer conv4_2_bn
I0516 19:48:10.343369 119433 net.cpp:406] conv4_2_bn <- conv4_2
I0516 19:48:10.343396 119433 net.cpp:367] conv4_2_bn -> conv4_2 (in-place)
I0516 19:48:10.343621 119433 net.cpp:122] Setting up conv4_2_bn
I0516 19:48:10.343633 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.343638 119433 net.cpp:137] Memory required for data: 325632000
I0516 19:48:10.343658 119433 layer_factory.hpp:77] Creating layer relu4_2
I0516 19:48:10.343677 119433 net.cpp:84] Creating Layer relu4_2
I0516 19:48:10.343685 119433 net.cpp:406] relu4_2 <- conv4_2
I0516 19:48:10.343703 119433 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0516 19:48:10.343888 119433 net.cpp:122] Setting up relu4_2
I0516 19:48:10.343900 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.343905 119433 net.cpp:137] Memory required for data: 328908800
I0516 19:48:10.343912 119433 layer_factory.hpp:77] Creating layer conv4_3
I0516 19:48:10.343968 119433 net.cpp:84] Creating Layer conv4_3
I0516 19:48:10.343979 119433 net.cpp:406] conv4_3 <- conv4_2
I0516 19:48:10.344002 119433 net.cpp:380] conv4_3 -> conv4_3
I0516 19:48:10.556594 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:10.556654 119433 net.cpp:122] Setting up conv4_3
I0516 19:48:10.556671 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.556675 119433 net.cpp:137] Memory required for data: 332185600
I0516 19:48:10.556696 119433 layer_factory.hpp:77] Creating layer conv4_3_bn
I0516 19:48:10.556726 119433 net.cpp:84] Creating Layer conv4_3_bn
I0516 19:48:10.556738 119433 net.cpp:406] conv4_3_bn <- conv4_3
I0516 19:48:10.556761 119433 net.cpp:367] conv4_3_bn -> conv4_3 (in-place)
I0516 19:48:10.556973 119433 net.cpp:122] Setting up conv4_3_bn
I0516 19:48:10.556984 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.556988 119433 net.cpp:137] Memory required for data: 335462400
I0516 19:48:10.557009 119433 layer_factory.hpp:77] Creating layer relu4_3
I0516 19:48:10.557027 119433 net.cpp:84] Creating Layer relu4_3
I0516 19:48:10.557034 119433 net.cpp:406] relu4_3 <- conv4_3
I0516 19:48:10.557049 119433 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0516 19:48:10.557703 119433 net.cpp:122] Setting up relu4_3
I0516 19:48:10.557718 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:10.557723 119433 net.cpp:137] Memory required for data: 338739200
I0516 19:48:10.557729 119433 layer_factory.hpp:77] Creating layer pool4
I0516 19:48:10.557739 119433 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0516 19:48:10.557759 119433 net.cpp:84] Creating Layer pool4
I0516 19:48:10.557766 119433 net.cpp:406] pool4 <- conv4_3
I0516 19:48:10.557785 119433 net.cpp:380] pool4 -> pool4
I0516 19:48:10.557806 119433 net.cpp:380] pool4 -> pool4_mask
I0516 19:48:10.557864 119433 net.cpp:122] Setting up pool4
I0516 19:48:10.557878 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.557884 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.557888 119433 net.cpp:137] Memory required for data: 340377600
I0516 19:48:10.557893 119433 layer_factory.hpp:77] Creating layer pool4_drop
I0516 19:48:10.557912 119433 net.cpp:84] Creating Layer pool4_drop
I0516 19:48:10.557920 119433 net.cpp:406] pool4_drop <- pool4
I0516 19:48:10.557948 119433 net.cpp:367] pool4_drop -> pool4 (in-place)
I0516 19:48:10.557988 119433 net.cpp:122] Setting up pool4_drop
I0516 19:48:10.557998 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.558001 119433 net.cpp:137] Memory required for data: 341196800
I0516 19:48:10.558007 119433 layer_factory.hpp:77] Creating layer conv5_1
I0516 19:48:10.558034 119433 net.cpp:84] Creating Layer conv5_1
I0516 19:48:10.558043 119433 net.cpp:406] conv5_1 <- pool4
I0516 19:48:10.558061 119433 net.cpp:380] conv5_1 -> conv5_1
I0516 19:48:10.769918 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:10.769958 119433 net.cpp:122] Setting up conv5_1
I0516 19:48:10.769973 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.769978 119433 net.cpp:137] Memory required for data: 342016000
I0516 19:48:10.769996 119433 layer_factory.hpp:77] Creating layer conv5_1_bn
I0516 19:48:10.770025 119433 net.cpp:84] Creating Layer conv5_1_bn
I0516 19:48:10.770035 119433 net.cpp:406] conv5_1_bn <- conv5_1
I0516 19:48:10.770056 119433 net.cpp:367] conv5_1_bn -> conv5_1 (in-place)
I0516 19:48:10.770267 119433 net.cpp:122] Setting up conv5_1_bn
I0516 19:48:10.770279 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.770283 119433 net.cpp:137] Memory required for data: 342835200
I0516 19:48:10.770303 119433 layer_factory.hpp:77] Creating layer relu5_1
I0516 19:48:10.770318 119433 net.cpp:84] Creating Layer relu5_1
I0516 19:48:10.770325 119433 net.cpp:406] relu5_1 <- conv5_1
I0516 19:48:10.770339 119433 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0516 19:48:10.770514 119433 net.cpp:122] Setting up relu5_1
I0516 19:48:10.770526 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.770530 119433 net.cpp:137] Memory required for data: 343654400
I0516 19:48:10.770537 119433 layer_factory.hpp:77] Creating layer conv5_2
I0516 19:48:10.770571 119433 net.cpp:84] Creating Layer conv5_2
I0516 19:48:10.770591 119433 net.cpp:406] conv5_2 <- conv5_1
I0516 19:48:10.770614 119433 net.cpp:380] conv5_2 -> conv5_2
I0516 19:48:10.983577 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:10.983613 119433 net.cpp:122] Setting up conv5_2
I0516 19:48:10.983626 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.983631 119433 net.cpp:137] Memory required for data: 344473600
I0516 19:48:10.983649 119433 layer_factory.hpp:77] Creating layer conv5_2_bn
I0516 19:48:10.983681 119433 net.cpp:84] Creating Layer conv5_2_bn
I0516 19:48:10.983693 119433 net.cpp:406] conv5_2_bn <- conv5_2
I0516 19:48:10.983714 119433 net.cpp:367] conv5_2_bn -> conv5_2 (in-place)
I0516 19:48:10.983913 119433 net.cpp:122] Setting up conv5_2_bn
I0516 19:48:10.983925 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.983929 119433 net.cpp:137] Memory required for data: 345292800
I0516 19:48:10.983947 119433 layer_factory.hpp:77] Creating layer relu5_2
I0516 19:48:10.983964 119433 net.cpp:84] Creating Layer relu5_2
I0516 19:48:10.983973 119433 net.cpp:406] relu5_2 <- conv5_2
I0516 19:48:10.983988 119433 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0516 19:48:10.984156 119433 net.cpp:122] Setting up relu5_2
I0516 19:48:10.984169 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:10.984174 119433 net.cpp:137] Memory required for data: 346112000
I0516 19:48:10.984179 119433 layer_factory.hpp:77] Creating layer conv5_3
I0516 19:48:10.984206 119433 net.cpp:84] Creating Layer conv5_3
I0516 19:48:10.984216 119433 net.cpp:406] conv5_3 <- conv5_2
I0516 19:48:10.984241 119433 net.cpp:380] conv5_3 -> conv5_3
I0516 19:48:11.196573 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:11.197059 119433 net.cpp:122] Setting up conv5_3
I0516 19:48:11.197077 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:11.197082 119433 net.cpp:137] Memory required for data: 346931200
I0516 19:48:11.197104 119433 layer_factory.hpp:77] Creating layer conv5_3_bn
I0516 19:48:11.197135 119433 net.cpp:84] Creating Layer conv5_3_bn
I0516 19:48:11.197146 119433 net.cpp:406] conv5_3_bn <- conv5_3
I0516 19:48:11.197167 119433 net.cpp:367] conv5_3_bn -> conv5_3 (in-place)
I0516 19:48:11.197404 119433 net.cpp:122] Setting up conv5_3_bn
I0516 19:48:11.197418 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:11.197422 119433 net.cpp:137] Memory required for data: 347750400
I0516 19:48:11.197477 119433 layer_factory.hpp:77] Creating layer relu5_3
I0516 19:48:11.197496 119433 net.cpp:84] Creating Layer relu5_3
I0516 19:48:11.197505 119433 net.cpp:406] relu5_3 <- conv5_3
I0516 19:48:11.197521 119433 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0516 19:48:11.198179 119433 net.cpp:122] Setting up relu5_3
I0516 19:48:11.198194 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:11.198200 119433 net.cpp:137] Memory required for data: 348569600
I0516 19:48:11.198209 119433 layer_factory.hpp:77] Creating layer pool5
I0516 19:48:11.198217 119433 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0516 19:48:11.198253 119433 net.cpp:84] Creating Layer pool5
I0516 19:48:11.198264 119433 net.cpp:406] pool5 <- conv5_3
I0516 19:48:11.198285 119433 net.cpp:380] pool5 -> pool5
I0516 19:48:11.198308 119433 net.cpp:380] pool5 -> pool5_mask
I0516 19:48:11.198390 119433 net.cpp:122] Setting up pool5
I0516 19:48:11.198415 119433 net.cpp:129] Top shape: 1 512 10 10 (51200)
I0516 19:48:11.198421 119433 net.cpp:129] Top shape: 1 512 10 10 (51200)
I0516 19:48:11.198426 119433 net.cpp:137] Memory required for data: 348979200
I0516 19:48:11.198432 119433 layer_factory.hpp:77] Creating layer pool5_drop
I0516 19:48:11.198449 119433 net.cpp:84] Creating Layer pool5_drop
I0516 19:48:11.198457 119433 net.cpp:406] pool5_drop <- pool5
I0516 19:48:11.198473 119433 net.cpp:367] pool5_drop -> pool5 (in-place)
I0516 19:48:11.198515 119433 net.cpp:122] Setting up pool5_drop
I0516 19:48:11.198525 119433 net.cpp:129] Top shape: 1 512 10 10 (51200)
I0516 19:48:11.198563 119433 net.cpp:137] Memory required for data: 349184000
I0516 19:48:11.198570 119433 layer_factory.hpp:77] Creating layer pool5_pool5_drop_0_split
I0516 19:48:11.198606 119433 net.cpp:84] Creating Layer pool5_pool5_drop_0_split
I0516 19:48:11.198612 119433 net.cpp:406] pool5_pool5_drop_0_split <- pool5
I0516 19:48:11.198628 119433 net.cpp:380] pool5_pool5_drop_0_split -> pool5_pool5_drop_0_split_0
I0516 19:48:11.198643 119433 net.cpp:380] pool5_pool5_drop_0_split -> pool5_pool5_drop_0_split_1
I0516 19:48:11.198696 119433 net.cpp:122] Setting up pool5_pool5_drop_0_split
I0516 19:48:11.198707 119433 net.cpp:129] Top shape: 1 512 10 10 (51200)
I0516 19:48:11.198714 119433 net.cpp:129] Top shape: 1 512 10 10 (51200)
I0516 19:48:11.198716 119433 net.cpp:137] Memory required for data: 349593600
I0516 19:48:11.198724 119433 layer_factory.hpp:77] Creating layer fc_1024
I0516 19:48:11.198746 119433 net.cpp:84] Creating Layer fc_1024
I0516 19:48:11.198755 119433 net.cpp:406] fc_1024 <- pool5_pool5_drop_0_split_0
I0516 19:48:11.198774 119433 net.cpp:380] fc_1024 -> fc_1024
I0516 19:48:16.198434 119433 net.cpp:122] Setting up fc_1024
I0516 19:48:16.198492 119433 net.cpp:129] Top shape: 1 1024 (1024)
I0516 19:48:16.198498 119433 net.cpp:137] Memory required for data: 349597696
I0516 19:48:16.198530 119433 layer_factory.hpp:77] Creating layer fc_512
I0516 19:48:16.198576 119433 net.cpp:84] Creating Layer fc_512
I0516 19:48:16.198597 119433 net.cpp:406] fc_512 <- fc_1024
I0516 19:48:16.198631 119433 net.cpp:380] fc_512 -> fc_512
I0516 19:48:16.255791 119433 net.cpp:122] Setting up fc_512
I0516 19:48:16.255844 119433 net.cpp:129] Top shape: 1 512 (512)
I0516 19:48:16.255849 119433 net.cpp:137] Memory required for data: 349599744
I0516 19:48:16.255877 119433 layer_factory.hpp:77] Creating layer fc_11
I0516 19:48:16.255923 119433 net.cpp:84] Creating Layer fc_11
I0516 19:48:16.255939 119433 net.cpp:406] fc_11 <- fc_512
I0516 19:48:16.255970 119433 net.cpp:380] fc_11 -> fc_11
I0516 19:48:16.256708 119433 net.cpp:122] Setting up fc_11
I0516 19:48:16.256729 119433 net.cpp:129] Top shape: 1 11 (11)
I0516 19:48:16.256734 119433 net.cpp:137] Memory required for data: 349599788
I0516 19:48:16.256750 119433 layer_factory.hpp:77] Creating layer upsample5
I0516 19:48:16.256789 119433 net.cpp:84] Creating Layer upsample5
I0516 19:48:16.256801 119433 net.cpp:406] upsample5 <- pool5_pool5_drop_0_split_1
I0516 19:48:16.256817 119433 net.cpp:406] upsample5 <- pool5_mask
I0516 19:48:16.256834 119433 net.cpp:380] upsample5 -> upsample5
I0516 19:48:16.256903 119433 net.cpp:122] Setting up upsample5
I0516 19:48:16.256917 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.256922 119433 net.cpp:137] Memory required for data: 350418988
I0516 19:48:16.256929 119433 layer_factory.hpp:77] Creating layer conv5_3_D
I0516 19:48:16.256961 119433 net.cpp:84] Creating Layer conv5_3_D
I0516 19:48:16.256971 119433 net.cpp:406] conv5_3_D <- upsample5
I0516 19:48:16.256997 119433 net.cpp:380] conv5_3_D -> conv5_3_D
I0516 19:48:16.497591 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:16.497648 119433 net.cpp:122] Setting up conv5_3_D
I0516 19:48:16.497668 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.497673 119433 net.cpp:137] Memory required for data: 351238188
I0516 19:48:16.497699 119433 layer_factory.hpp:77] Creating layer conv5_3_D_bn
I0516 19:48:16.497740 119433 net.cpp:84] Creating Layer conv5_3_D_bn
I0516 19:48:16.497753 119433 net.cpp:406] conv5_3_D_bn <- conv5_3_D
I0516 19:48:16.497786 119433 net.cpp:367] conv5_3_D_bn -> conv5_3_D (in-place)
I0516 19:48:16.498033 119433 net.cpp:122] Setting up conv5_3_D_bn
I0516 19:48:16.498045 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.498049 119433 net.cpp:137] Memory required for data: 352057388
I0516 19:48:16.498070 119433 layer_factory.hpp:77] Creating layer relu5_3_D
I0516 19:48:16.498088 119433 net.cpp:84] Creating Layer relu5_3_D
I0516 19:48:16.498096 119433 net.cpp:406] relu5_3_D <- conv5_3_D
I0516 19:48:16.498122 119433 net.cpp:367] relu5_3_D -> conv5_3_D (in-place)
I0516 19:48:16.498365 119433 net.cpp:122] Setting up relu5_3_D
I0516 19:48:16.498381 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.498389 119433 net.cpp:137] Memory required for data: 352876588
I0516 19:48:16.498396 119433 layer_factory.hpp:77] Creating layer conv5_2_D
I0516 19:48:16.498428 119433 net.cpp:84] Creating Layer conv5_2_D
I0516 19:48:16.498440 119433 net.cpp:406] conv5_2_D <- conv5_3_D
I0516 19:48:16.498466 119433 net.cpp:380] conv5_2_D -> conv5_2_D
I0516 19:48:16.739378 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:16.739426 119433 net.cpp:122] Setting up conv5_2_D
I0516 19:48:16.739444 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.739450 119433 net.cpp:137] Memory required for data: 353695788
I0516 19:48:16.739475 119433 layer_factory.hpp:77] Creating layer conv5_2_D_bn
I0516 19:48:16.739516 119433 net.cpp:84] Creating Layer conv5_2_D_bn
I0516 19:48:16.739532 119433 net.cpp:406] conv5_2_D_bn <- conv5_2_D
I0516 19:48:16.739560 119433 net.cpp:367] conv5_2_D_bn -> conv5_2_D (in-place)
I0516 19:48:16.739792 119433 net.cpp:122] Setting up conv5_2_D_bn
I0516 19:48:16.739804 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.739809 119433 net.cpp:137] Memory required for data: 354514988
I0516 19:48:16.739828 119433 layer_factory.hpp:77] Creating layer relu5_2_D
I0516 19:48:16.739848 119433 net.cpp:84] Creating Layer relu5_2_D
I0516 19:48:16.739857 119433 net.cpp:406] relu5_2_D <- conv5_2_D
I0516 19:48:16.739872 119433 net.cpp:367] relu5_2_D -> conv5_2_D (in-place)
I0516 19:48:16.740064 119433 net.cpp:122] Setting up relu5_2_D
I0516 19:48:16.740077 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.740082 119433 net.cpp:137] Memory required for data: 355334188
I0516 19:48:16.740092 119433 layer_factory.hpp:77] Creating layer conv5_1_D
I0516 19:48:16.740124 119433 net.cpp:84] Creating Layer conv5_1_D
I0516 19:48:16.740135 119433 net.cpp:406] conv5_1_D <- conv5_2_D
I0516 19:48:16.740159 119433 net.cpp:380] conv5_1_D -> conv5_1_D
I0516 19:48:16.979619 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:16.979674 119433 net.cpp:122] Setting up conv5_1_D
I0516 19:48:16.979694 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.979699 119433 net.cpp:137] Memory required for data: 356153388
I0516 19:48:16.979727 119433 layer_factory.hpp:77] Creating layer conv5_1_D_bn
I0516 19:48:16.979768 119433 net.cpp:84] Creating Layer conv5_1_D_bn
I0516 19:48:16.979784 119433 net.cpp:406] conv5_1_D_bn <- conv5_1_D
I0516 19:48:16.979817 119433 net.cpp:367] conv5_1_D_bn -> conv5_1_D (in-place)
I0516 19:48:16.980082 119433 net.cpp:122] Setting up conv5_1_D_bn
I0516 19:48:16.980096 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.980101 119433 net.cpp:137] Memory required for data: 356972588
I0516 19:48:16.980123 119433 layer_factory.hpp:77] Creating layer relu5_1_D
I0516 19:48:16.980144 119433 net.cpp:84] Creating Layer relu5_1_D
I0516 19:48:16.980152 119433 net.cpp:406] relu5_1_D <- conv5_1_D
I0516 19:48:16.980168 119433 net.cpp:367] relu5_1_D -> conv5_1_D (in-place)
I0516 19:48:16.980906 119433 net.cpp:122] Setting up relu5_1_D
I0516 19:48:16.980926 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.980931 119433 net.cpp:137] Memory required for data: 357791788
I0516 19:48:16.980939 119433 layer_factory.hpp:77] Creating layer conv5_1_D_drop
I0516 19:48:16.980964 119433 net.cpp:84] Creating Layer conv5_1_D_drop
I0516 19:48:16.980973 119433 net.cpp:406] conv5_1_D_drop <- conv5_1_D
I0516 19:48:16.980994 119433 net.cpp:367] conv5_1_D_drop -> conv5_1_D (in-place)
I0516 19:48:16.981046 119433 net.cpp:122] Setting up conv5_1_D_drop
I0516 19:48:16.981057 119433 net.cpp:129] Top shape: 1 512 20 20 (204800)
I0516 19:48:16.981061 119433 net.cpp:137] Memory required for data: 358610988
I0516 19:48:16.981068 119433 layer_factory.hpp:77] Creating layer upsample4
I0516 19:48:16.981096 119433 net.cpp:84] Creating Layer upsample4
I0516 19:48:16.981117 119433 net.cpp:406] upsample4 <- conv5_1_D
I0516 19:48:16.981132 119433 net.cpp:406] upsample4 <- pool4_mask
I0516 19:48:16.981148 119433 net.cpp:380] upsample4 -> upsample4
I0516 19:48:16.981204 119433 net.cpp:122] Setting up upsample4
I0516 19:48:16.981218 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:16.981223 119433 net.cpp:137] Memory required for data: 361887788
I0516 19:48:16.981230 119433 layer_factory.hpp:77] Creating layer conv4_3_D
I0516 19:48:16.981302 119433 net.cpp:84] Creating Layer conv4_3_D
I0516 19:48:16.981313 119433 net.cpp:406] conv4_3_D <- upsample4
I0516 19:48:16.981335 119433 net.cpp:380] conv4_3_D -> conv4_3_D
I0516 19:48:17.226028 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:17.226064 119433 net.cpp:122] Setting up conv4_3_D
I0516 19:48:17.226081 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:17.226086 119433 net.cpp:137] Memory required for data: 365164588
I0516 19:48:17.226114 119433 layer_factory.hpp:77] Creating layer conv4_3_D_bn
I0516 19:48:17.226155 119433 net.cpp:84] Creating Layer conv4_3_D_bn
I0516 19:48:17.226171 119433 net.cpp:406] conv4_3_D_bn <- conv4_3_D
I0516 19:48:17.226202 119433 net.cpp:367] conv4_3_D_bn -> conv4_3_D (in-place)
I0516 19:48:17.226454 119433 net.cpp:122] Setting up conv4_3_D_bn
I0516 19:48:17.226469 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:17.226474 119433 net.cpp:137] Memory required for data: 368441388
I0516 19:48:17.226495 119433 layer_factory.hpp:77] Creating layer relu4_3_D
I0516 19:48:17.226512 119433 net.cpp:84] Creating Layer relu4_3_D
I0516 19:48:17.226521 119433 net.cpp:406] relu4_3_D <- conv4_3_D
I0516 19:48:17.226536 119433 net.cpp:367] relu4_3_D -> conv4_3_D (in-place)
I0516 19:48:17.226732 119433 net.cpp:122] Setting up relu4_3_D
I0516 19:48:17.226747 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:17.226752 119433 net.cpp:137] Memory required for data: 371718188
I0516 19:48:17.226759 119433 layer_factory.hpp:77] Creating layer conv4_2_D
I0516 19:48:17.226793 119433 net.cpp:84] Creating Layer conv4_2_D
I0516 19:48:17.226804 119433 net.cpp:406] conv4_2_D <- conv4_3_D
I0516 19:48:17.226827 119433 net.cpp:380] conv4_2_D -> conv4_2_D
I0516 19:48:17.439621 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55296
I0516 19:48:17.439661 119433 net.cpp:122] Setting up conv4_2_D
I0516 19:48:17.439680 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:17.439685 119433 net.cpp:137] Memory required for data: 374994988
I0516 19:48:17.439705 119433 layer_factory.hpp:77] Creating layer conv4_2_D_bn
I0516 19:48:17.439743 119433 net.cpp:84] Creating Layer conv4_2_D_bn
I0516 19:48:17.439754 119433 net.cpp:406] conv4_2_D_bn <- conv4_2_D
I0516 19:48:17.439779 119433 net.cpp:367] conv4_2_D_bn -> conv4_2_D (in-place)
I0516 19:48:17.439999 119433 net.cpp:122] Setting up conv4_2_D_bn
I0516 19:48:17.440011 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:17.440016 119433 net.cpp:137] Memory required for data: 378271788
I0516 19:48:17.440033 119433 layer_factory.hpp:77] Creating layer relu4_2_D
I0516 19:48:17.440053 119433 net.cpp:84] Creating Layer relu4_2_D
I0516 19:48:17.440062 119433 net.cpp:406] relu4_2_D <- conv4_2_D
I0516 19:48:17.440075 119433 net.cpp:367] relu4_2_D -> conv4_2_D (in-place)
I0516 19:48:17.440255 119433 net.cpp:122] Setting up relu4_2_D
I0516 19:48:17.440269 119433 net.cpp:129] Top shape: 1 512 40 40 (819200)
I0516 19:48:17.440274 119433 net.cpp:137] Memory required for data: 381548588
I0516 19:48:17.440280 119433 layer_factory.hpp:77] Creating layer conv4_1_D
I0516 19:48:17.440309 119433 net.cpp:84] Creating Layer conv4_1_D
I0516 19:48:17.440318 119433 net.cpp:406] conv4_1_D <- conv4_2_D
I0516 19:48:17.440340 119433 net.cpp:380] conv4_1_D -> conv4_1_D
I0516 19:48:17.547752 119433 net.cpp:122] Setting up conv4_1_D
I0516 19:48:17.547775 119433 net.cpp:129] Top shape: 1 256 40 40 (409600)
I0516 19:48:17.547788 119433 net.cpp:137] Memory required for data: 383186988
I0516 19:48:17.547813 119433 layer_factory.hpp:77] Creating layer conv4_1_D_bn
I0516 19:48:17.547835 119433 net.cpp:84] Creating Layer conv4_1_D_bn
I0516 19:48:17.547845 119433 net.cpp:406] conv4_1_D_bn <- conv4_1_D
I0516 19:48:17.547866 119433 net.cpp:367] conv4_1_D_bn -> conv4_1_D (in-place)
I0516 19:48:17.548087 119433 net.cpp:122] Setting up conv4_1_D_bn
I0516 19:48:17.548099 119433 net.cpp:129] Top shape: 1 256 40 40 (409600)
I0516 19:48:17.548102 119433 net.cpp:137] Memory required for data: 384825388
I0516 19:48:17.548120 119433 layer_factory.hpp:77] Creating layer relu4_1_D
I0516 19:48:17.548135 119433 net.cpp:84] Creating Layer relu4_1_D
I0516 19:48:17.548142 119433 net.cpp:406] relu4_1_D <- conv4_1_D
I0516 19:48:17.548158 119433 net.cpp:367] relu4_1_D -> conv4_1_D (in-place)
I0516 19:48:17.548791 119433 net.cpp:122] Setting up relu4_1_D
I0516 19:48:17.548820 119433 net.cpp:129] Top shape: 1 256 40 40 (409600)
I0516 19:48:17.548825 119433 net.cpp:137] Memory required for data: 386463788
I0516 19:48:17.548835 119433 layer_factory.hpp:77] Creating layer conv_final_64_D
I0516 19:48:17.548862 119433 net.cpp:84] Creating Layer conv_final_64_D
I0516 19:48:17.548873 119433 net.cpp:406] conv_final_64_D <- conv4_1_D
I0516 19:48:17.548899 119433 net.cpp:380] conv_final_64_D -> conv_final_64_D
I0516 19:48:17.552119 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3072
I0516 19:48:17.552598 119433 net.cpp:122] Setting up conv_final_64_D
I0516 19:48:17.552614 119433 net.cpp:129] Top shape: 1 64 40 40 (102400)
I0516 19:48:17.552619 119433 net.cpp:137] Memory required for data: 386873388
I0516 19:48:17.552634 119433 layer_factory.hpp:77] Creating layer conv4_final_64_D_bn
I0516 19:48:17.552667 119433 net.cpp:84] Creating Layer conv4_final_64_D_bn
I0516 19:48:17.552678 119433 net.cpp:406] conv4_final_64_D_bn <- conv_final_64_D
I0516 19:48:17.552700 119433 net.cpp:367] conv4_final_64_D_bn -> conv_final_64_D (in-place)
I0516 19:48:17.552950 119433 net.cpp:122] Setting up conv4_final_64_D_bn
I0516 19:48:17.552973 119433 net.cpp:129] Top shape: 1 64 40 40 (102400)
I0516 19:48:17.552978 119433 net.cpp:137] Memory required for data: 387282988
I0516 19:48:17.552995 119433 layer_factory.hpp:77] Creating layer relu_final_64_D
I0516 19:48:17.553011 119433 net.cpp:84] Creating Layer relu_final_64_D
I0516 19:48:17.553019 119433 net.cpp:406] relu_final_64_D <- conv_final_64_D
I0516 19:48:17.553032 119433 net.cpp:367] relu_final_64_D -> conv_final_64_D (in-place)
I0516 19:48:17.553220 119433 net.cpp:122] Setting up relu_final_64_D
I0516 19:48:17.553249 119433 net.cpp:129] Top shape: 1 64 40 40 (102400)
I0516 19:48:17.553256 119433 net.cpp:137] Memory required for data: 387692588
I0516 19:48:17.553262 119433 layer_factory.hpp:77] Creating layer conv_final_48_D
I0516 19:48:17.553289 119433 net.cpp:84] Creating Layer conv_final_48_D
I0516 19:48:17.553300 119433 net.cpp:406] conv_final_48_D <- conv_final_64_D
I0516 19:48:17.553323 119433 net.cpp:380] conv_final_48_D -> conv_final_48_D
I0516 19:48:17.555374 119433 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 768
I0516 19:48:17.555403 119433 net.cpp:122] Setting up conv_final_48_D
I0516 19:48:17.555416 119433 net.cpp:129] Top shape: 1 48 40 40 (76800)
I0516 19:48:17.555421 119433 net.cpp:137] Memory required for data: 387999788
I0516 19:48:17.555434 119433 layer_factory.hpp:77] Creating layer conv4_final_48_D_bn
I0516 19:48:17.555452 119433 net.cpp:84] Creating Layer conv4_final_48_D_bn
I0516 19:48:17.555460 119433 net.cpp:406] conv4_final_48_D_bn <- conv_final_48_D
I0516 19:48:17.555480 119433 net.cpp:367] conv4_final_48_D_bn -> conv_final_48_D (in-place)
I0516 19:48:17.555712 119433 net.cpp:122] Setting up conv4_final_48_D_bn
I0516 19:48:17.555724 119433 net.cpp:129] Top shape: 1 48 40 40 (76800)
I0516 19:48:17.555728 119433 net.cpp:137] Memory required for data: 388306988
I0516 19:48:17.555745 119433 layer_factory.hpp:77] Creating layer relu_final_48_D
I0516 19:48:17.555759 119433 net.cpp:84] Creating Layer relu_final_48_D
I0516 19:48:17.555773 119433 net.cpp:406] relu_final_48_D <- conv_final_48_D
I0516 19:48:17.555794 119433 net.cpp:367] relu_final_48_D -> conv_final_48_D (in-place)
I0516 19:48:17.555981 119433 net.cpp:122] Setting up relu_final_48_D
I0516 19:48:17.555994 119433 net.cpp:129] Top shape: 1 48 40 40 (76800)
I0516 19:48:17.555999 119433 net.cpp:137] Memory required for data: 388614188
I0516 19:48:17.556005 119433 layer_factory.hpp:77] Creating layer heatmap_visualize
I0516 19:48:17.556023 119433 net.cpp:84] Creating Layer heatmap_visualize
I0516 19:48:17.556031 119433 net.cpp:406] heatmap_visualize <- conv_final_48_D
I0516 19:48:17.556051 119433 net.cpp:380] heatmap_visualize -> heatmap_visualize
I0516 19:48:17.556072 119433 net.cpp:122] Setting up heatmap_visualize
I0516 19:48:17.556082 119433 net.cpp:129] Top shape: (1)
I0516 19:48:17.556085 119433 net.cpp:137] Memory required for data: 388614192
I0516 19:48:17.556092 119433 layer_factory.hpp:77] Creating layer prob
I0516 19:48:17.556113 119433 net.cpp:84] Creating Layer prob
I0516 19:48:17.556120 119433 net.cpp:406] prob <- fc_11
I0516 19:48:17.556138 119433 net.cpp:380] prob -> prob
I0516 19:48:17.556239 119433 net.cpp:122] Setting up prob
I0516 19:48:17.556252 119433 net.cpp:129] Top shape: 1 11 (11)
I0516 19:48:17.556257 119433 net.cpp:137] Memory required for data: 388614236
I0516 19:48:17.556268 119433 net.cpp:200] prob does not need backward computation.
I0516 19:48:17.556275 119433 net.cpp:200] heatmap_visualize does not need backward computation.
I0516 19:48:17.556280 119433 net.cpp:200] relu_final_48_D does not need backward computation.
I0516 19:48:17.556284 119433 net.cpp:200] conv4_final_48_D_bn does not need backward computation.
I0516 19:48:17.556289 119433 net.cpp:200] conv_final_48_D does not need backward computation.
I0516 19:48:17.556293 119433 net.cpp:200] relu_final_64_D does not need backward computation.
I0516 19:48:17.556298 119433 net.cpp:200] conv4_final_64_D_bn does not need backward computation.
I0516 19:48:17.556303 119433 net.cpp:200] conv_final_64_D does not need backward computation.
I0516 19:48:17.556308 119433 net.cpp:200] relu4_1_D does not need backward computation.
I0516 19:48:17.556313 119433 net.cpp:200] conv4_1_D_bn does not need backward computation.
I0516 19:48:17.556316 119433 net.cpp:200] conv4_1_D does not need backward computation.
I0516 19:48:17.556320 119433 net.cpp:200] relu4_2_D does not need backward computation.
I0516 19:48:17.556325 119433 net.cpp:200] conv4_2_D_bn does not need backward computation.
I0516 19:48:17.556329 119433 net.cpp:200] conv4_2_D does not need backward computation.
I0516 19:48:17.556334 119433 net.cpp:200] relu4_3_D does not need backward computation.
I0516 19:48:17.556339 119433 net.cpp:200] conv4_3_D_bn does not need backward computation.
I0516 19:48:17.556344 119433 net.cpp:200] conv4_3_D does not need backward computation.
I0516 19:48:17.556349 119433 net.cpp:200] upsample4 does not need backward computation.
I0516 19:48:17.556354 119433 net.cpp:200] conv5_1_D_drop does not need backward computation.
I0516 19:48:17.556358 119433 net.cpp:200] relu5_1_D does not need backward computation.
I0516 19:48:17.556363 119433 net.cpp:200] conv5_1_D_bn does not need backward computation.
I0516 19:48:17.556368 119433 net.cpp:200] conv5_1_D does not need backward computation.
I0516 19:48:17.556372 119433 net.cpp:200] relu5_2_D does not need backward computation.
I0516 19:48:17.556377 119433 net.cpp:200] conv5_2_D_bn does not need backward computation.
I0516 19:48:17.556382 119433 net.cpp:200] conv5_2_D does not need backward computation.
I0516 19:48:17.556387 119433 net.cpp:200] relu5_3_D does not need backward computation.
I0516 19:48:17.556391 119433 net.cpp:200] conv5_3_D_bn does not need backward computation.
I0516 19:48:17.556396 119433 net.cpp:200] conv5_3_D does not need backward computation.
I0516 19:48:17.556401 119433 net.cpp:200] upsample5 does not need backward computation.
I0516 19:48:17.556407 119433 net.cpp:200] fc_11 does not need backward computation.
I0516 19:48:17.556417 119433 net.cpp:200] fc_512 does not need backward computation.
I0516 19:48:17.556428 119433 net.cpp:200] fc_1024 does not need backward computation.
I0516 19:48:17.556434 119433 net.cpp:200] pool5_pool5_drop_0_split does not need backward computation.
I0516 19:48:17.556439 119433 net.cpp:200] pool5_drop does not need backward computation.
I0516 19:48:17.556445 119433 net.cpp:200] pool5 does not need backward computation.
I0516 19:48:17.556450 119433 net.cpp:200] relu5_3 does not need backward computation.
I0516 19:48:17.556455 119433 net.cpp:200] conv5_3_bn does not need backward computation.
I0516 19:48:17.556462 119433 net.cpp:200] conv5_3 does not need backward computation.
I0516 19:48:17.556466 119433 net.cpp:200] relu5_2 does not need backward computation.
I0516 19:48:17.556471 119433 net.cpp:200] conv5_2_bn does not need backward computation.
I0516 19:48:17.556475 119433 net.cpp:200] conv5_2 does not need backward computation.
I0516 19:48:17.556481 119433 net.cpp:200] relu5_1 does not need backward computation.
I0516 19:48:17.556485 119433 net.cpp:200] conv5_1_bn does not need backward computation.
I0516 19:48:17.556490 119433 net.cpp:200] conv5_1 does not need backward computation.
I0516 19:48:17.556495 119433 net.cpp:200] pool4_drop does not need backward computation.
I0516 19:48:17.556502 119433 net.cpp:200] pool4 does not need backward computation.
I0516 19:48:17.556509 119433 net.cpp:200] relu4_3 does not need backward computation.
I0516 19:48:17.556514 119433 net.cpp:200] conv4_3_bn does not need backward computation.
I0516 19:48:17.556517 119433 net.cpp:200] conv4_3 does not need backward computation.
I0516 19:48:17.556522 119433 net.cpp:200] relu4_2 does not need backward computation.
I0516 19:48:17.556527 119433 net.cpp:200] conv4_2_bn does not need backward computation.
I0516 19:48:17.556532 119433 net.cpp:200] conv4_2 does not need backward computation.
I0516 19:48:17.556537 119433 net.cpp:200] relu4_1 does not need backward computation.
I0516 19:48:17.556542 119433 net.cpp:200] conv4_1_bn does not need backward computation.
I0516 19:48:17.556546 119433 net.cpp:200] conv4_1 does not need backward computation.
I0516 19:48:17.556552 119433 net.cpp:200] pool3_drop does not need backward computation.
I0516 19:48:17.556557 119433 net.cpp:200] pool3 does not need backward computation.
I0516 19:48:17.556562 119433 net.cpp:200] relu3_3 does not need backward computation.
I0516 19:48:17.556567 119433 net.cpp:200] conv3_3_bn does not need backward computation.
I0516 19:48:17.556572 119433 net.cpp:200] conv3_3 does not need backward computation.
I0516 19:48:17.556577 119433 net.cpp:200] relu3_2 does not need backward computation.
I0516 19:48:17.556582 119433 net.cpp:200] conv3_2_bn does not need backward computation.
I0516 19:48:17.556587 119433 net.cpp:200] conv3_2 does not need backward computation.
I0516 19:48:17.556592 119433 net.cpp:200] relu3_1 does not need backward computation.
I0516 19:48:17.556597 119433 net.cpp:200] conv3_1_bn does not need backward computation.
I0516 19:48:17.556602 119433 net.cpp:200] conv3_1 does not need backward computation.
I0516 19:48:17.556607 119433 net.cpp:200] pool2 does not need backward computation.
I0516 19:48:17.556612 119433 net.cpp:200] relu2_2 does not need backward computation.
I0516 19:48:17.556617 119433 net.cpp:200] conv2_2_bn does not need backward computation.
I0516 19:48:17.556622 119433 net.cpp:200] conv2_2 does not need backward computation.
I0516 19:48:17.556627 119433 net.cpp:200] relu2_1 does not need backward computation.
I0516 19:48:17.556632 119433 net.cpp:200] conv2_1_bn does not need backward computation.
I0516 19:48:17.556637 119433 net.cpp:200] conv2_1 does not need backward computation.
I0516 19:48:17.556641 119433 net.cpp:200] pool1 does not need backward computation.
I0516 19:48:17.556648 119433 net.cpp:200] relu1_2 does not need backward computation.
I0516 19:48:17.556653 119433 net.cpp:200] conv1_2_bn does not need backward computation.
I0516 19:48:17.556656 119433 net.cpp:200] conv1_2 does not need backward computation.
I0516 19:48:17.556663 119433 net.cpp:200] relu1_1 does not need backward computation.
I0516 19:48:17.556674 119433 net.cpp:200] conv1_1_bn does not need backward computation.
I0516 19:48:17.556679 119433 net.cpp:200] conv1_1 does not need backward computation.
I0516 19:48:17.556684 119433 net.cpp:200] data does not need backward computation.
I0516 19:48:17.556689 119433 net.cpp:242] This network produces output heatmap_visualize
I0516 19:48:17.556699 119433 net.cpp:242] This network produces output prob
I0516 19:48:17.556784 119433 net.cpp:255] Network initialization done.
I0516 19:48:21.108106 119433 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: snapshots_std5_swap_iter_60000.caffemodel
I0516 19:48:21.108186 119433 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0516 19:48:21.108198 119433 net.cpp:747] Copying source layer data
I0516 19:48:21.108224 119433 net.cpp:744] Ignoring source layer type_data_2_split
I0516 19:48:21.108228 119433 net.cpp:747] Copying source layer conv1_1
I0516 19:48:21.108324 119433 net.cpp:747] Copying source layer conv1_1_bn
I0516 19:48:21.108340 119433 net.cpp:747] Copying source layer relu1_1
I0516 19:48:21.108346 119433 net.cpp:747] Copying source layer conv1_2
I0516 19:48:21.108826 119433 net.cpp:747] Copying source layer conv1_2_bn
I0516 19:48:21.108841 119433 net.cpp:747] Copying source layer relu1_2
I0516 19:48:21.108847 119433 net.cpp:747] Copying source layer pool1
I0516 19:48:21.108852 119433 net.cpp:747] Copying source layer conv2_1
I0516 19:48:21.109835 119433 net.cpp:747] Copying source layer conv2_1_bn
I0516 19:48:21.109853 119433 net.cpp:747] Copying source layer relu2_1
I0516 19:48:21.109858 119433 net.cpp:747] Copying source layer conv2_2
I0516 19:48:21.111636 119433 net.cpp:747] Copying source layer conv2_2_bn
I0516 19:48:21.111655 119433 net.cpp:747] Copying source layer relu2_2
I0516 19:48:21.111661 119433 net.cpp:747] Copying source layer pool2
I0516 19:48:21.111666 119433 net.cpp:747] Copying source layer conv3_1
I0516 19:48:21.115085 119433 net.cpp:747] Copying source layer conv3_1_bn
I0516 19:48:21.115106 119433 net.cpp:747] Copying source layer relu3_1
I0516 19:48:21.115111 119433 net.cpp:747] Copying source layer conv3_2
I0516 19:48:21.121644 119433 net.cpp:747] Copying source layer conv3_2_bn
I0516 19:48:21.121667 119433 net.cpp:747] Copying source layer relu3_2
I0516 19:48:21.121673 119433 net.cpp:747] Copying source layer conv3_3
I0516 19:48:21.128029 119433 net.cpp:747] Copying source layer conv3_3_bn
I0516 19:48:21.128051 119433 net.cpp:747] Copying source layer relu3_3
I0516 19:48:21.128057 119433 net.cpp:747] Copying source layer pool3
I0516 19:48:21.128062 119433 net.cpp:747] Copying source layer pool3_drop
I0516 19:48:21.128067 119433 net.cpp:747] Copying source layer conv4_1
I0516 19:48:21.141466 119433 net.cpp:747] Copying source layer conv4_1_bn
I0516 19:48:21.141496 119433 net.cpp:747] Copying source layer relu4_1
I0516 19:48:21.141502 119433 net.cpp:747] Copying source layer conv4_2
I0516 19:48:21.166265 119433 net.cpp:747] Copying source layer conv4_2_bn
I0516 19:48:21.166313 119433 net.cpp:747] Copying source layer relu4_2
I0516 19:48:21.166321 119433 net.cpp:747] Copying source layer conv4_3
I0516 19:48:21.191030 119433 net.cpp:747] Copying source layer conv4_3_bn
I0516 19:48:21.191079 119433 net.cpp:747] Copying source layer relu4_3
I0516 19:48:21.191085 119433 net.cpp:747] Copying source layer pool4
I0516 19:48:21.191092 119433 net.cpp:747] Copying source layer pool4_drop
I0516 19:48:21.191097 119433 net.cpp:747] Copying source layer conv5_1
I0516 19:48:21.216106 119433 net.cpp:747] Copying source layer conv5_1_bn
I0516 19:48:21.216150 119433 net.cpp:747] Copying source layer relu5_1
I0516 19:48:21.216156 119433 net.cpp:747] Copying source layer conv5_2
I0516 19:48:21.241576 119433 net.cpp:747] Copying source layer conv5_2_bn
I0516 19:48:21.241623 119433 net.cpp:747] Copying source layer relu5_2
I0516 19:48:21.241629 119433 net.cpp:747] Copying source layer conv5_3
I0516 19:48:21.266515 119433 net.cpp:747] Copying source layer conv5_3_bn
I0516 19:48:21.266573 119433 net.cpp:747] Copying source layer relu5_3
I0516 19:48:21.266593 119433 net.cpp:747] Copying source layer pool5
I0516 19:48:21.266598 119433 net.cpp:747] Copying source layer pool5_drop
I0516 19:48:21.266603 119433 net.cpp:747] Copying source layer pool5_pool5_drop_0_split
I0516 19:48:21.266608 119433 net.cpp:747] Copying source layer fc_1024
I0516 19:48:21.819255 119433 net.cpp:747] Copying source layer fc_512
I0516 19:48:21.824864 119433 net.cpp:747] Copying source layer fc_11
I0516 19:48:21.824945 119433 net.cpp:747] Copying source layer upsample5
I0516 19:48:21.824961 119433 net.cpp:747] Copying source layer conv5_3_D
I0516 19:48:21.849921 119433 net.cpp:747] Copying source layer conv5_3_D_bn
I0516 19:48:21.849967 119433 net.cpp:747] Copying source layer relu5_3_D
I0516 19:48:21.849977 119433 net.cpp:747] Copying source layer conv5_2_D
I0516 19:48:21.875038 119433 net.cpp:747] Copying source layer conv5_2_D_bn
I0516 19:48:21.875078 119433 net.cpp:747] Copying source layer relu5_2_D
I0516 19:48:21.875084 119433 net.cpp:747] Copying source layer conv5_1_D
I0516 19:48:21.899988 119433 net.cpp:747] Copying source layer conv5_1_D_bn
I0516 19:48:21.900032 119433 net.cpp:747] Copying source layer relu5_1_D
I0516 19:48:21.900038 119433 net.cpp:747] Copying source layer conv5_1_D_drop
I0516 19:48:21.900043 119433 net.cpp:747] Copying source layer upsample4
I0516 19:48:21.900048 119433 net.cpp:747] Copying source layer conv4_3_D
I0516 19:48:21.925004 119433 net.cpp:747] Copying source layer conv4_3_D_bn
I0516 19:48:21.925045 119433 net.cpp:747] Copying source layer relu4_3_D
I0516 19:48:21.925051 119433 net.cpp:747] Copying source layer conv4_2_D
I0516 19:48:21.950276 119433 net.cpp:747] Copying source layer conv4_2_D_bn
I0516 19:48:21.950320 119433 net.cpp:747] Copying source layer relu4_2_D
I0516 19:48:21.950326 119433 net.cpp:747] Copying source layer conv4_1_D
I0516 19:48:21.963021 119433 net.cpp:747] Copying source layer conv4_1_D_bn
I0516 19:48:21.963050 119433 net.cpp:747] Copying source layer relu4_1_D
I0516 19:48:21.963055 119433 net.cpp:747] Copying source layer conv_final_64_D
I0516 19:48:21.963255 119433 net.cpp:747] Copying source layer conv4_final_64_D_bn
I0516 19:48:21.963270 119433 net.cpp:747] Copying source layer relu_final_64_D
I0516 19:48:21.963277 119433 net.cpp:747] Copying source layer conv_final_48_D
I0516 19:48:21.963323 119433 net.cpp:747] Copying source layer conv4_final_48_D_bn
I0516 19:48:21.963335 119433 net.cpp:747] Copying source layer relu_final_48_D
I0516 19:48:21.963341 119433 net.cpp:744] Ignoring source layer keypoint_loss
I0516 19:48:21.963346 119433 net.cpp:744] Ignoring source layer type_loss
I0516 19:48:21.987591 119433 caffe.cpp:290] Running for 1 iterations.
I0516 19:48:21.988786 119436 data_heatmap_test.cpp:111] img: /data01/vision_rd/zhangfengyang/roomnet/LSUN/images/sun_adxkgdkocvlrjoil.jpg
I0516 19:48:22.009699 119436 data_heatmap_test.cpp:147] Resizing output image.
I0516 19:48:22.009760 119436 data_heatmap_test.cpp:152] resizeFact_x: 0.3125
I0516 19:48:22.009816 119436 data_heatmap_test.cpp:153] resizeFact_y: 0.416667
I0516 19:48:22.024799 119436 data_heatmap_test.cpp:165] storing image
I0516 19:48:22.030067 119436 data_heatmap_test.cpp:177] next image
I0516 19:48:22.030124 119436 data_heatmap_test.cpp:185] Prefetch batch: 41 ms.
I0516 19:48:22.133683 119433 heatmap_visualize_layer.cpp:47] bottom size: 40 40 48
I0516 19:48:22.139570 119433 caffe.cpp:313] Batch 0, heatmap_visualize = 0
I0516 19:48:22.139643 119433 caffe.cpp:313] Batch 0, prob = 0.021623
I0516 19:48:22.139657 119433 caffe.cpp:313] Batch 0, prob = 0.0482997
I0516 19:48:22.139662 119433 caffe.cpp:313] Batch 0, prob = 0.000678062
I0516 19:48:22.139668 119433 caffe.cpp:313] Batch 0, prob = 0.0061479
I0516 19:48:22.139673 119433 caffe.cpp:313] Batch 0, prob = 0.666803
I0516 19:48:22.139678 119433 caffe.cpp:313] Batch 0, prob = 0.157844
I0516 19:48:22.139683 119433 caffe.cpp:313] Batch 0, prob = 0.00985652
I0516 19:48:22.139688 119433 caffe.cpp:313] Batch 0, prob = 0.00108545
I0516 19:48:22.139698 119433 caffe.cpp:313] Batch 0, prob = 0.000733417
I0516 19:48:22.139714 119433 caffe.cpp:313] Batch 0, prob = 0.0751742
I0516 19:48:22.139719 119433 caffe.cpp:313] Batch 0, prob = 0.011755
I0516 19:48:22.139724 119433 caffe.cpp:318] Loss: 0
I0516 19:48:22.139734 119433 caffe.cpp:330] heatmap_visualize = 0
I0516 19:48:22.139741 119433 caffe.cpp:330] prob = 0.021623
I0516 19:48:22.139746 119433 caffe.cpp:330] prob = 0.0482997
I0516 19:48:22.139750 119433 caffe.cpp:330] prob = 0.000678062
I0516 19:48:22.139755 119433 caffe.cpp:330] prob = 0.0061479
I0516 19:48:22.139760 119433 caffe.cpp:330] prob = 0.666803
I0516 19:48:22.139765 119433 caffe.cpp:330] prob = 0.157844
I0516 19:48:22.139768 119433 caffe.cpp:330] prob = 0.00985652
I0516 19:48:22.139773 119433 caffe.cpp:330] prob = 0.00108545
I0516 19:48:22.139777 119433 caffe.cpp:330] prob = 0.000733417
I0516 19:48:22.139782 119433 caffe.cpp:330] prob = 0.0751742
I0516 19:48:22.139786 119433 caffe.cpp:330] prob = 0.011755
I0516 19:48:22.145416 119433 data_heatmap_test.cpp:35] ++++++++++++++++++++++++++++++++++++++++
*** Aborted at 1494935302 (unix time) try "date -d @1494935302" if you are using GNU date ***
PC: @     0x7f65f03261d7 __GI_raise
*** SIGABRT (@0x3e80001d289) received by PID 119433 (TID 0x7f66058cc9c0) from PID 119433; stack trace: ***
    @     0x7f65f06c1370 (unknown)
    @     0x7f65f03261d7 __GI_raise
    @     0x7f65f03278c8 __GI_abort
    @     0x7f65f0365f07 __libc_message
    @     0x7f65f036d503 _int_free
    @           0x427cd0 __gnu_cxx::new_allocator<>::deallocate()
    @           0x4254dc std::_Vector_base<>::_M_deallocate()
    @           0x422f6a std::_Vector_base<>::~_Vector_base()
    @           0x420ac4 std::vector<>::~vector()
    @     0x7f6604b27c85 caffe::Blob<>::~Blob()
    @     0x7f6604b85701 caffe::Batch<>::~Batch()
    @     0x7f6604bffdd5 caffe::RoomnetPrefetchingTestLayer<>::~RoomnetPrefetchingTestLayer()
    @     0x7f6604c4a47f caffe::DataHeatmapTestLayer<>::~DataHeatmapTestLayer()
    @     0x7f6604c4a51a caffe::DataHeatmapTestLayer<>::~DataHeatmapTestLayer()
    @     0x7f6604c4d256 boost::checked_delete<>()
    @     0x7f6604c4d3ee boost::detail::sp_counted_impl_p<>::dispose()
    @           0x41f210 boost::detail::sp_counted_base::release()
    @           0x41f29f boost::detail::shared_count::~shared_count()
    @           0x42de38 boost::shared_ptr<>::~shared_ptr()
    @           0x42de52 std::_Destroy<>()
    @           0x42c4f6 std::_Destroy_aux<>::__destroy<>()
    @           0x429b13 std::_Destroy<>()
    @           0x426e3b std::_Destroy<>()
    @           0x424718 std::vector<>::~vector()
    @           0x421993 caffe::Net<>::~Net()
    @           0x41cd08 test()
    @           0x41e167 main
    @     0x7f65f0312b35 __libc_start_main
    @           0x41aa69 (unknown)
